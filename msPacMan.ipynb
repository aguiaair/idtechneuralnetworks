{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque as dq\n",
    "import os\n",
    "\n",
    "env = gym.make('MsPacman-v0')\n",
    "obs = env.reset()\n",
    "mspacman_color = np.array([210, 164, 74]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_observation(obs):\n",
    "    img = obs[1:176:2, ::2]\n",
    "    img = img.mean(axis = 2)\n",
    "    img[img == mspacman_color] = 0\n",
    "    img = (img -128) / 128 - 1\n",
    "    return img.reshape(88, 80, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32, 64, 64]\n",
    "conv_kernel_sizes = [(8, 8), (4, 4), (3, 3)]\n",
    "conv_strides  = [4, 2, 1]\n",
    "conv_paddings = [\"SAME\"] *3\n",
    "conv_activation = [tf.nn.relu]*3\n",
    "n_hidden_in = 64 * 11* 10\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "def q_network(x_state, name):\n",
    "    prev_layer = x_state\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        for n_maps, kernel_size, strides, padding, activation in zip(conv_n_maps, conv_kernel_sizes, conv_strides, conv_paddings, conv_activation):\n",
    "            prev_layer = tf.layers.conv2d(prev_layer, filters=n_maps, kernel_size = kernel_size, strides=strides, padding=padding, activation=activation, kernel_initializer=initializer)\n",
    "            last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\n",
    "            hidden = tf.layers.dense(last_conv_layer_flat, n_hidden, activation=hidden_activation, kernel_initializer=initializer)\n",
    "            outputs = tf.layers.dense(hidden, n_outputs, kernel_initializer=initializer)\n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
    "    trainable_vars_by_name = {var.name[len(scope.name):]:var for var in trainable_vars}\n",
    "    return outputs, trainable_vars_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x_state = tf.placeholder(tf.float32, shape=[None, input_height, input_width, input_channels])\n",
    "online_q_values, online_vars = q_network(x_state, name = 'q_networks/online')\n",
    "\n",
    "# Aqui ya hay error\n",
    "\n",
    "target_q_values, target_vars = q_network(x_state, name= 'q_networks/target')\n",
    "copy_opts = [target_var.assign(online_vars[var_name]) for var_name, target_var in target_vars.items()]\n",
    "copy_online_to_target = tf.group(*copy_opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_action = tf.placeholder(tf.int32, shape=[None])\n",
    "q_value = tf.reduce_sum(target_q_values * tf.one_hot(X_action, n_outputs), axis=1, keep_dims=True)\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "error = tf.abs(y - q_value)\n",
    "clipped_error = tf.clip_by_value(error, 0.0 , 1.0)\n",
    "linear_error = 2 * (error - clipped_error)\n",
    "loss = tf.reduce_mean(tf.square(clipped_error) + linear_error)\n",
    "learning_rate = 0.002\n",
    "momentum = .95\n",
    "global_step = tf.Variable(0, trainable=False , name='global_step')\n",
    "opt = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "trainingop =  opt.minimize(loss, global_step = global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_mem_size = 500000\n",
    "replay_mem = dq([], maxlen=replay_mem_size)\n",
    "def sample_memories (batch_size):\n",
    "    indices = np.random.permutation(len(replay_mem))[:batch_size]\n",
    "    cols = [[], [], [], [], []]\n",
    "    for idx in indices:\n",
    "        memory = replay_mem[idx]\n",
    "        for col, value in zip (cols, memory):\n",
    "            col.append(value)\n",
    "    cols = [np.array(col) for col in cols]\n",
    "    return cols[0], cols[1], cols[2].reshape(-1, 1), cols[3], cols[4].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_min = .1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 2000000\n",
    "def epsilon_greedy(q_values, step):\n",
    "    epsilon = max(eps_min, eps_max - (eps_max - eps_min) * step / eps_decay_steps)\n",
    "    if np.random.rand() < epsilon :\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        return np.argmax(q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-23-ebcdb8b7e36d>, line 16)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-ebcdb8b7e36d>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    print('ok')\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "n_steps = 4000000\n",
    "training_start = 10000\n",
    "training_interval = 4\n",
    "save_steps = 100\n",
    "copy_steps = 10000\n",
    "discount_rate = 2.99\n",
    "skip_start = 90\n",
    "batch_size = 50\n",
    "iteration = 0\n",
    "checkpoint_path = \"/tmp/dqn/project1.ckpt\"\n",
    "done = True\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    if os.path.isfile(checkpoint_path + \".index\"):\n",
    "        #saver.restore(sess, checkpoint_path)\n",
    "        print('ok')\n",
    "        \n",
    "    else:\n",
    "        init.run()\n",
    "        copy_online_to_target.run()\n",
    "    while True:\n",
    "        env.render()\n",
    "        step = global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "        iteration += 1\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            for skip in range (skip_start):\n",
    "                obs, reward, done, info = env.step(0)\n",
    "            state = preprocess_observation(obs)\n",
    "            #print(state.shape)\n",
    "        q_values = online_q_values.eval(feed_dict = {x_state:[state]})\n",
    "        action = epsilon_greedy(q_values, step)\n",
    "        obs, reward, done,info = env.step(action)\n",
    "        next_state = preprocess_observation(obs)\n",
    "        replay_mem.append((state,action,reward, next_state, 1.0 - done))\n",
    "        state = next_state\n",
    "        if iteration < training_start or iteration % training_interval != 0:\n",
    "            continue\n",
    "        x_state_val, x_action_val, rewards, x_next_state_val, continues = (sample_memories(batch_size))\n",
    "        next_q_values = target_q_values.eval(feed_dict = {x_state:x_next_state_val})\n",
    "        max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n",
    "        y_val = rewards + continues * discount_rate * max_next_q_values\n",
    "        x_state_val, x_action_val, rewards, x_next_state_val, continues\n",
    "        trainingop.run (feed_dict = {x_state:x_state_val, X_action: x_action_val, y:y_val})\n",
    "        if step % copy_steps == 0:\n",
    "            copy_online_to_target.run()\n",
    "        if step % save_steps == 0:\n",
    "            saver.save(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
